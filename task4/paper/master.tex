\documentclass[10pt,oneside,a4paper,final,english]{memoir}

\input{env/packages}
\input{env/forloop}
\input{env/languages}
\input{env/graphics}
\input{env/math}
\input{env/bibtex}

\usepackage{datetime}

\chapterstyle{thatcher}

\setcounter{secnumdepth}{0}
\setcounter{tocdepth}{0}




%\pagestyle{fancy}
\begin{document}
  \fontencoding{T1}
%  \fontseries{m}
%  \fontshape{n}
%  \fontsize{12}{15}
%  \selectfont


\input{env/preamble}

\maketitle
\newpage

\section{Introduction}
The goal of this assignment was to implement the DogLeg method and
compare this to the two methods implemented so far.

\section{Trust Region Methods}
As we have seen in earlier studies of optimization methods an easy to
compute decent direction can be found in the inverse direction of the
gradient, that being $-g$. However, using this direction does not come
without complications. First, the direction is only guaranteed to
decent within some $\epsilon$ of the original point. Secondly, even if
one finds an $\epsilon$ that yields the greatest decent in the
objective function and follows this to what is known as the Cauchy
point, the method can still be slow; zigzagging its way to a local
minimum.

An alternative search direction is Newton's direction. As many other
line search methods it uses a search direction described by:
\[ p_k = -B^{-1} \nabla f(x_k) \]

Both of these methods are line search methods. They compute a decent
direction and then decides on an appropriate step size. The method
investigated in this assignment is known as a trust region method. Put
shortly, it decides on a step size and then compute the a decent
direction within the step size (the ``region'').

The idea is to use a model function $m$ that approximates the
objective function $f$. Knowing the step size $\lambda$, the goal is
to find the best search direction in the model function (which is easy
to minimize) and then follow this direction in $f$. Of cause one needs
to verify that the model is in fact precise enough to yield a decent
in $f$. If not, the $\lambda$ is lowered. $\lambda$ is a measure for
the precision of the model function. The region containing points with
a distance lower than $\lambda$ away from $x_k$ is called the
``trust'' region.


\section{Dog-Leg Method}
The Dog-Leg method is based on a combination of the Cauchy point and
a Quasi-Newton method. It will choose its search direction based on
the following three cases:
\begin{enumerate}
\item When the point suggested by Newton's method is within the trust
  region, this point is selected.
\item If this is not the case and the trust region requests a smaller
  step than that of the Cauchy point, the direction towards this point
  is followed as far as the region permits.
\item In the third case, when the region boundary is between the
  Cauchy point and the Newton point, the intersection between the
  limiting boundary and the line between these two points are chosen.
\end{enumerate}

As can be seen, the possible directions is given by two joined lines
(from $p_k$ to the Cauchy point and further to Newton's point). This
gives a bending line (a ``dog leg'').

Specifically, $p_k$ may take one of the following forms:
\begin{enumerate}
\item \[ p_{k+1} = p^B \]
\item \[ p_{k+1} = \frac{\Delta}{\mid p^U\mid}  p^U \]
\item \[ p_{k+1} = p^U + \frac{\Delta - \mid p^U\mid}{
    \mid p^B\mid + 2p^{U\prime} p^B} p^B \]
\end{enumerate}

Where $\Delta$ is the size of the trust region, $p^B$ is the point
suggested by Newton's method and $p^U$ is the Cauchy point. The two
latter points are defined as:
\[ p^B = -B \cdot \nabla f (x_k) \]
\[ p^C =  \]



Where $B$ is an approximation of the Hessian; a positive definite
matrix.



\section{Verification}


\section{Conclusion}

\section{Implementation}
This section contains the MatLab code for the BFGS implementation. I
also updated the source code for the other two methods slightly,
however I considered the changes too small to include here.

\subsection{DogLeg Method}
\verbatiminput{../code/dogleg.m}


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
